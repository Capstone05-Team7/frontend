package com.example.capstone07.ui.speech

import android.Manifest
import android.content.Context
import android.content.pm.PackageManager
import android.graphics.Bitmap
import android.graphics.BitmapFactory
import android.media.AudioFormat
import android.media.AudioRecord
import android.media.MediaRecorder
import android.os.Bundle
import android.os.Handler
import android.os.Looper
import android.util.Base64
import android.util.Log
import android.view.LayoutInflater
import android.view.View
import android.view.ViewGroup
import android.widget.Toast
import androidx.activity.result.ActivityResultLauncher
import androidx.activity.result.contract.ActivityResultContracts
import androidx.annotation.RequiresPermission
import androidx.core.content.ContextCompat
import androidx.fragment.app.Fragment
import androidx.lifecycle.lifecycleScope
import com.example.capstone07.R
import com.example.capstone07.data.AppDatabase
import com.example.capstone07.data.ImageCacheDao
import com.example.capstone07.databinding.FragmentAnalysisBinding
import com.example.capstone07.model.ImageCacheEntity
import com.example.capstone07.model.ScriptResponseFragment
import com.example.capstone07.remote.PresentationStompClient
import com.example.capstone07.remote.ProgressResponse
import com.example.capstone07.remote.SimilarityResponse
import com.google.android.gms.wearable.Asset
import com.google.android.gms.wearable.PutDataMapRequest
import com.google.android.gms.wearable.Wearable
import com.google.android.gms.tasks.Tasks
import com.google.api.gax.core.FixedCredentialsProvider
import com.google.api.gax.rpc.ApiStreamObserver
import com.google.auth.oauth2.GoogleCredentials
import com.google.protobuf.ByteString
import com.google.cloud.speech.v1.RecognitionConfig
import com.google.cloud.speech.v1.SpeechClient
import com.google.cloud.speech.v1.SpeechSettings
import com.google.cloud.speech.v1.StreamingRecognitionConfig
import com.google.cloud.speech.v1.StreamingRecognizeRequest
import com.google.cloud.speech.v1.StreamingRecognizeResponse
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.launch
import kotlinx.coroutines.withContext
import java.io.ByteArrayOutputStream
import java.io.File
import java.io.FileOutputStream
import java.io.InputStream
import java.net.HttpURLConnection
import java.net.URL
import java.nio.ByteBuffer
import java.security.MessageDigest
import java.util.concurrent.LinkedBlockingQueue


class AnalysisFragment : Fragment() {

    /**
     * ë³€ìˆ˜ ë° ìƒìˆ˜
     */

    private var _binding: FragmentAnalysisBinding? = null
    private val binding get() = _binding!!

    // ë°›ì•„ì˜¤ëŠ” ìŠ¤í¬ë¦½íŠ¸ ì •ë³´
    val scripts = arguments?.getParcelableArrayList<ScriptResponseFragment>("scripts")

    // ì´ë¯¸ì§€ ìºì‹± ê´€ë ¨
    private lateinit var imageCacheDao: ImageCacheDao

    // for Google Cloud STT
    private var speechClient: SpeechClient? = null
    private var requestObserver: ApiStreamObserver<StreamingRecognizeRequest>? = null

    // for AudioRecord
    private var audioRecord: AudioRecord? = null
    private val sampleRate = 16000 // STT APIê°€ ê¶Œì¥í•˜ëŠ” í‘œì¤€ ìƒ˜í”Œ ë ˆì´íŠ¸
    private val channelConfig = AudioFormat.CHANNEL_IN_MONO
    private val audioFormat = AudioFormat.ENCODING_PCM_16BIT
    private var bufferSize = 0

    // STTì— í•„ìš”í•œ ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ìš©
    private lateinit var requestPermissionLauncher: ActivityResultLauncher<String>

    // ë§ˆì´í¬ ì¸ì‹ ìƒíƒœ
    private var isListening = false

    // ì›¹ì†Œì¼“ í´ë¼ì´ì–¸íŠ¸ ê°ì²´
    private lateinit var stompClient: PresentationStompClient
    // ë°œí‘œ ID (ì•„ë§ˆ projectIdë¥¼ ì“¸ ê²ƒ ê°™ì€ë°, íŠ¹ì • í”„ë¡œì íŠ¸ ì¡°íšŒ apiê°€ ì—†ì–´ì„œ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ í•˜ë“œì½”ë”©)
    private var PRESENTATION_ID: String = "1"

    private val TAG = "AnalysisFragment"

    // UI ìŠ¤ë ˆë“œì—ì„œ ë™ì‘í•  í•¸ë“¤ëŸ¬
    private val hintHandler = Handler(Looper.getMainLooper())

    private val recognizedSpeechBuffer = StringBuilder()

    // ---ë²„í¼ ê´€ë¦¬ë¥¼ ìœ„í•œ ìƒìˆ˜---
    private val MAX_WORD_COUNT = 20 // ìµœëŒ€ í—ˆìš© ë‹¨ì–´ ìˆ˜
    private val TRIM_WORD_COUNT = 10 // ì‚­ì œí•  ë‹¨ì–´ ìˆ˜ (MAX_WORD_COUNTì˜ ì ˆë°˜)

    // --- í˜„ì¬ ìƒíƒœ ì €ì¥ìš© ---
    private var speakingSentence: String = ""   // í˜„ì¬ ë§í•˜ê³  ìˆëŠ” ë¬¸ì¥
    private var speakingId: String = ""     // ë°œí™” ì¤‘ì¸ ë¬¸ì¥ id

    // --- '2-ìŠ¤ë ˆë“œ ì•„í‚¤í…ì²˜'ë¥¼ ìœ„í•œ ë³€ìˆ˜ ---
    private val audioBuffer = LinkedBlockingQueue<ByteArray>()  // [ìŠ¤ë ˆë“œ A]ê°€ ë…¹ìŒí•œ ì˜¤ë””ì˜¤ ì²­í¬ë¥¼ ë‹´ì•„ë‘ëŠ” 'ê³µìš© ë°”êµ¬ë‹ˆ'
    private var audioRecordingThread: Thread? = null    // [ìŠ¤ë ˆë“œ A] AudioRecordì—ì„œ ë§ˆì´í¬ ì…ë ¥ì„ ì½ì–´ audioBufferì— ë„£ëŠ” ì—­í• 
    private var sttTransmissionThread: Thread? = null   // [ìŠ¤ë ˆë“œ B] audioBufferì—ì„œ ì˜¤ë””ì˜¤ë¥¼ êº¼ë‚´ Google STT ì„œë²„ë¡œ ì „ì†¡í•˜ëŠ” ì—­í• 

    // --- ê°ì‹œì ë„ì… ---
    private var lastSttResponseTime = 0L    // ë§ˆì§€ë§‰ìœ¼ë¡œ ì„œë²„ ì‘ë‹µ(onNext)ì„ ë°›ì€ ì‹œê°„
    private val watchdogHandler = Handler(Looper.getMainLooper())   // 3.5ì´ˆ ë™ì•ˆ ì‘ë‹µ ì—†ìœ¼ë©´ ì¬ì‹œì‘ì‹œí‚¤ëŠ” ê°ì‹œì
    private val watchdogRunnable = object : Runnable {
        override fun run() {
            if (isListening) {
                val currentTime = System.currentTimeMillis()
                // (ì£¼ì‹œì‘ ì§í›„ 3ì´ˆê°„ì€ ë¬´ì‹œ (ì—°ê²° ì´ˆê¸°í™” ì‹œê°„ ê³ ë ¤)
                if (currentTime - lastSttResponseTime > 3000) {
                    /*Log.w(TAG, "[ê°ì‹œì] 3ì´ˆê°„ ì‘ë‹µ ì—†ìŒ. ì „ì†¡ ìŠ¤ë ˆë“œ ì¬ì‹œì‘")

                    // ì „ì†¡ ìŠ¤ë ˆë“œë§Œ ë¦¬ì…‹ (ë…¹ìŒì€ ê³„ì†ë¨ -> ëŠê¹€ ì—†ìŒ)
                    startSttTransmission()

                    // ì‹œê°„ ê°±ì‹ 
                    lastSttResponseTime = System.currentTimeMillis()*/

                    // â­ï¸ [í•µì‹¬ ìˆ˜ì •] íì— ë°ì´í„°ê°€ ìŒ“ì—¬ìˆëŠ”ë°ë„(>0) ì‘ë‹µì´ ì—†ìœ¼ë©´ ì§„ì§œ ë¬¸ì œ!
                    // íê°€ ë¹„ì–´ìˆë‹¤ë©´(=ì‚¬ìš©ìê°€ ë§ì„ ì•ˆ í•´ì„œ ë³´ë‚¼ ê²Œ ì—†ìœ¼ë©´) ì‘ë‹µ ì—†ëŠ” ê±´ ë‹¹ì—°í•¨.
                    if (audioBuffer.isNotEmpty()) {
                        Log.w(TAG, "[ê°ì‹œì] íì— ë°ì´í„°ê°€ ${audioBuffer.size}ê°œë‚˜ ìˆëŠ”ë° ì‘ë‹µ ì—†ìŒ. ì¬ì‹œì‘")
                        startSttTransmission()
                        lastSttResponseTime = System.currentTimeMillis()
                    } else {
                        // íê°€ ë¹„ì–´ìˆìœ¼ë©´ ê·¸ëƒ¥ ì‹œê°„ë§Œ ê°±ì‹ í•´ì„œ ì‚´ë ¤ë‘  (False Alarm ë°©ì§€)
                        // Log.v(TAG, "[ê°ì‹œì] ì‘ë‹µ ì—†ì§€ë§Œ íë„ ë¹„ì–´ìˆìŒ(ì¹¨ë¬µ ì¤‘). íŒ¨ìŠ¤.")
                        lastSttResponseTime = System.currentTimeMillis()
                    }
                }
                // 1ì´ˆë§ˆë‹¤ ê°ì‹œ
                watchdogHandler.postDelayed(this, 1000)
            }
        }
    }

    // ë¬¸ì¥ ì¡°ê°ì„ ëª¨ìœ¼ëŠ” ë³€ìˆ˜
    private val accumulatedScript = StringBuilder()



    /**
     * ---------ë©”ì†Œë“œë“¤-----------
     */
    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)

        imageCacheDao = AppDatabase.getDatabase(requireContext()).imageCacheDao()

        // ê¶Œí•œ ìš”ì²­ ëŸ°ì²˜ ë“±ë¡
        requestPermissionLauncher = registerForActivityResult(
            ActivityResultContracts.RequestPermission()
        ) { isGranted: Boolean ->
            // ê¶Œí•œ ìš”ì²­ ê²°ê³¼ ì²˜ë¦¬
            if (isGranted) {
                // ê¶Œí•œ íšë“ ì‹œ ë°”ë¡œ ì‹œì‘
                checkMicrophonePermissionAndStartSTT()
            } else {
                Toast.makeText(requireContext(), "ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.", Toast.LENGTH_SHORT).show()
            }
        }
    }

    override fun onCreateView(
        inflater: LayoutInflater,
        container: ViewGroup?,
        savedInstanceState: Bundle?
    ): View {
        _binding = FragmentAnalysisBinding.inflate(inflater, container, false)
        return binding.root
    }

    override fun onViewCreated(view: View, savedInstanceState: Bundle?) {
        super.onViewCreated(view, savedInstanceState)

        PRESENTATION_ID = arguments
            ?.getInt("projectId")
            ?.toString()
            ?: "1"

        val scripts =
            arguments?.getParcelableArrayList<ScriptResponseFragment>("scripts")
                ?: return

        val appContext = requireContext().applicationContext

        // ì´ë¯¸ì§€ ìºì‹± ì™„ë£Œ ì „ê¹Œì§€ ë§ˆì´í¬ ë¹„í™œì„±í™”
        binding.imageViewMic.isEnabled = false

        viewLifecycleOwner.lifecycleScope.launch(Dispatchers.IO) {

            withContext(Dispatchers.Main) {
                binding.progressLoading.visibility = View.VISIBLE
                binding.imageViewMic.visibility = View.INVISIBLE
                binding.imageViewMic.isEnabled = false
            }

            // imageCacheDao.clearAll()         // DB ì´ˆê¸°í™”
            // clearAllCachedImages(appContext) // ì‹œì‘í•˜ê¸° ì „ ì´ë¯¸ ìˆëŠ” ìºì‹œ ì´ë¯¸ì§€ë“¤ ì‚­ì œ

            val jobs = scripts.map { script ->
                launch {
                    val sentenceId = script.sentenceId
                    val imageUrl = script.image
                    Log.d("Image", "ì´ë¯¸ì§€ ê²½ë¡œ:, path=$imageUrl")

                    if (imageCacheDao.exists(PRESENTATION_ID.toInt(), sentenceId)) {
                        Log.w("ImageCache", "â­ï¸ ì´ë¯¸ DBì— ì¡´ì¬í•´ì„œ ìŠ¤í‚µë¨: id=$sentenceId")
                        return@launch
                    }

                    try {
                        val bitmap = downloadBitmap(imageUrl)
                        val path = saveBitmap(appContext, bitmap, PRESENTATION_ID.toInt(), sentenceId)
                        Log.d("ImageCache", "ğŸ“‚ íŒŒì¼ ì €ì¥ ì™„ë£Œ: id=$sentenceId, path=$path")

                        imageCacheDao.insert(
                            ImageCacheEntity(
                                projectId = PRESENTATION_ID.toInt(),
                                sentenceId = sentenceId,
                                filePath = path
                            )
                        )

                    } catch (e: Exception) {
                        Log.e("ImageCache", "ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: id=$id", e)
                    }
                }
            }

            jobs.forEach { it.join() }

            withContext(Dispatchers.Main) {
                binding.progressLoading.visibility = View.GONE
                binding.imageViewMic.visibility = View.VISIBLE
                binding.imageViewMic.isEnabled = true

                // ì›¹ì†Œì¼“ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ë° ì—°ê²°
                stompClient = PresentationStompClient(PRESENTATION_ID, ::onHintReceived, ::onProgressReceived)
                stompClient.connect()
            }
        }

        binding.textViewNowspeaking.text = speakingSentence

        // STT í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ)
        Thread {
            setupStreamingSTT()
        }.start()

        // ì²˜ìŒì—” ì¤‘ë‹¨ ë²„íŠ¼ ìˆ¨ê¸°ê¸°
        binding.imageViewStop.visibility = View.GONE

        // ë§ˆì´í¬ í´ë¦­ ì²˜ë¦¬
        binding.imageViewMic.setOnClickListener {
            if (!isListening) {
                // ê¶Œí•œ í™•ì¸ í›„ STT ì‹œì‘
                checkMicrophonePermissionAndStartSTT()
            }
        }

        // ì¤‘ë‹¨ ë²„íŠ¼ í´ë¦­ ì²˜ë¦¬
        binding.imageViewStop.setOnClickListener {
            stopStreamingAudio()    // STT ì¤‘ë‹¨
            stompClient.disconnect() // ì›¹ì†Œì¼“ ì—°ê²° í•´ì œ
        }
    }

    /**
     * Google Cloud STT í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
     * (ì¸ì¦ íŒŒì¼ I/Oê°€ ìˆìœ¼ë¯€ë¡œ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ í˜¸ì¶œí•´ì•¼ í•¨)
     */
    private fun setupStreamingSTT() {
        try {
            // ì¸ì¦ íŒŒì¼(credential.json) ë¡œë”©
            val credentialsStream = requireContext().resources.openRawResource(R.raw.credential)
            val credentials = GoogleCredentials.fromStream(credentialsStream)

            // ì¸ì¦ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ SpeechSettings ìƒì„±
            val speechSettings = SpeechSettings.newBuilder()
                .setCredentialsProvider(FixedCredentialsProvider.create(credentials))
                .build()

            // SpeechClient ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            speechClient = SpeechClient.create(speechSettings)
            Log.d(TAG, "SpeechClient ì´ˆê¸°í™” ì„±ê³µ")

        } catch (e: Exception) {
            Log.e(TAG, "SpeechClient ì´ˆê¸°í™” ì‹¤íŒ¨", e)
            // ì˜¤ë¥˜
            activity?.runOnUiThread {
                Toast.makeText(requireContext(), "STT ì´ˆê¸°í™” ì‹¤íŒ¨. ì•±ì„ ì¬ì‹œì‘í•˜ì„¸ìš”.", Toast.LENGTH_LONG).show()
            }
        }
    }

    // ë§ˆì´í¬ ê¶Œí•œ í™•ì¸ ë° STT ì‹œì‘
    private fun checkMicrophonePermissionAndStartSTT() {
        if (ContextCompat.checkSelfPermission(requireContext(), android.Manifest.permission.RECORD_AUDIO)
            == PackageManager.PERMISSION_GRANTED) {

            // SpeechClient ì´ˆê¸°í™”
            if (speechClient == null) {
                Toast.makeText(requireContext(), "STT ì—”ì§„ì„ ì´ˆê¸°í™” ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.", Toast.LENGTH_SHORT).show()
                Thread { setupStreamingSTT() }.start() // ì¬ì‹œë„
                return
            }

            // ë…¹ìŒ ë° ì˜¤ë””ì˜¤ ìŠ¤ë ˆë“œ, STT ì „ì†¡ ìŠ¤ë ˆë“œ ì‹œì‘
            startStreamingAudio()
        } else {
            requestPermissionLauncher.launch(android.Manifest.permission.RECORD_AUDIO)
        }
    }

    /**
     * Google Cloud STT ì„œë²„ë¡œë¶€í„° ì‹¤ì‹œê°„ ì‘ë‹µ(ë³€í™˜ í…ìŠ¤íŠ¸)ì„ ìˆ˜ì‹ í•˜ëŠ” ì½œë°± ê°ì²´
     */
    private val responseObserver = object : ApiStreamObserver<StreamingRecognizeResponse> {

        /**
         * ì„œë²„ì—ì„œ STT ê²°ê³¼ê°€ ë„ì°©í–ˆì„ ë•Œ í˜¸ì¶œ
         * (ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰)
         */
        override fun onNext(response: StreamingRecognizeResponse) {
            // ìµœê·¼ ì‘ë‹µ ì‹œê°„ ê°±ì‹ 
            lastSttResponseTime = System.currentTimeMillis()

            // ìœ íš¨í•œ ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸
            val result = response.resultsList.firstOrNull()
            if (result == null || result.alternativesList.isEmpty()) {
                return
            }

            // ì¸ì‹ëœ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            val transcript = result.alternativesList[0].transcript.trim()

            // UI ìŠ¤ë ˆë“œë¡œ ì „í™˜í•˜ì—¬ ì‘ì—…
            activity?.runOnUiThread {
                if (result.isFinal) {
                    // --- 'ìµœì¢…' ê²°ê³¼ (onResultsì™€ ìœ ì‚¬) ---
                    Log.d(TAG, "[ìµœì¢…] $transcript")

                    // ë²„í¼ ëˆ„ì  ë° ì§„í–‰ë¥  ê³„ì‚°
                    recognizedSpeechBuffer.append(transcript).append(" ")
                    //trimSpeechBufferIfNeeded()  // ë²„í¼ ê´€ë¦¬
                    val textToSend = recognizedSpeechBuffer.toString().trim()

                    stompClient.sendSttTextForProgress(speakingId, speakingSentence, textToSend)

                } else {
                    // --- 'ì¤‘ê°„' ê²°ê³¼ (onPartialResultsì™€ ìœ ì‚¬) ---
                    Log.d(TAG, "[ì¤‘ê°„] $transcript")

                    // ì¡ìŒ í•„í„°ë§ í•´ì„œ STT ì „ì†¡
                    if (isMeaningfulSpeech(transcript)) {
                        stompClient.sendSttText(transcript) // STT ì „ì†¡
                        //stompClient.sendSttTextForProgress(speakingId, speakingSentence, transcript) // ì§„í–‰ë¥  ê³„ì‚°
                    }
                }
            }
        }

        /** ì˜¤ë¥˜ ë°œìƒ ì‹œ  */
        override fun onError(t: Throwable) {
            Log.e(TAG, "STT ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜", t)
            // ì‚¬ìš©ìê°€ ì¤‘ì§€í•œ ê²Œ ì•„ë‹ˆë¼ë©´, ì „ì†¡ ìŠ¤ë ˆë“œë§Œ ì¬ì‹œì‘
            if (isListening) {
                activity?.runOnUiThread { startSttTransmission() }
            }
        }

        /** ìŠ¤íŠ¸ë¦¼ì´ ì •ìƒ ì¢…ë£Œë˜ì—ˆì„ ë•Œ (ì¬ì‹œì‘) */
        override fun onCompleted() {
            Log.d(TAG, "STT ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ")
            // ì‚¬ìš©ìê°€ ì¤‘ì§€í•œ ê²Œ ì•„ë‹ˆë¼ë©´, ì „ì†¡ ìŠ¤ë ˆë“œë§Œ ì¬ì‹œì‘
            if (isListening) {
                activity?.runOnUiThread { startSttTransmission() }
            }
        }
    }

    /**
     * STT ê²°ê³¼ê°€ ì¡ìŒì´ë‚˜ ì§§ì€ ê°íƒ„ì‚¬ê°€ ì•„ë‹Œ ìœ ì˜ë¯¸í•œ ë°œí™”ì¸ì§€ íŒë‹¨í•©ë‹ˆë‹¤.
     * @param text STT ì—”ì§„ìœ¼ë¡œë¶€í„° ìˆ˜ì‹ ëœ í…ìŠ¤íŠ¸
     * @return ìœ ì˜ë¯¸í•˜ë©´ true, ì¡ìŒì„± í…ìŠ¤íŠ¸ë©´ false
     */
    private fun isMeaningfulSpeech(text: String): Boolean {
        // ì „ì²˜ë¦¬: êµ¬ë‘ì ê³¼ ê³µë°±ì„ ì œê±°í•˜ì—¬ ì‹¤ì œ ë‚´ìš©ë¬¼ë§Œ ë¹„êµí•  ìˆ˜ ìˆë„ë¡ ì •ê·œí™”
        // êµ¬ë‘ì ê³¼ ê³µë°±ì„ ì œê±°í•´ë„ í…ìŠ¤íŠ¸ê°€ ë‚¨ì•„ìˆëŠ”ì§€ í™•ì¸
        val normalizedText = text.replace(Regex("[\\s.,?!:;\"'\\-_]"), "").trim()

        // ìµœì†Œ ê¸¸ì´ ê²€ì‚¬ (ì •ê·œí™”ëœ í…ìŠ¤íŠ¸ ê¸°ì¤€)
        // 2ê¸€ì ë¯¸ë§Œì€ ëŒ€ë¶€ë¶„ ì¡ìŒ ("ì•„", "ìŒ" ë“±)
        if (normalizedText.length < 20) {
            //Log.v(TAG, "FILTERED: ì§§ì€ ê¸¸ì´ ($normalizedText)")
            return false
        }

        // ë°˜ë³µë˜ëŠ” ë¬¸ìì—´ ê²€ì‚¬ (ì •ê·œí™”ëœ í…ìŠ¤íŠ¸ ê¸°ì¤€)
        // "ã…‹ã…‹ã…‹", "ì•„ì•„ì•„", "......" ë“± ì˜ë¯¸ ì—†ëŠ” ë°˜ë³µ
        if (normalizedText.all { it == normalizedText.first() } && normalizedText.length > 1) {
            Log.v(TAG, "FILTERED: ë°˜ë³µ ë¬¸ìì—´ ($normalizedText)")
            return false
        }

        // ì¡ìŒ/ê°íƒ„ì‚¬ íŒ¨í„´ ê²€ì‚¬
        // 'ì•„', 'ì—', 'ì´', 'ì˜¤', 'ìš°', 'ìŒ', 'í ', 'í' ë“±ìœ¼ë¡œë§Œ ì´ë£¨ì–´ì§„ íŒ¨í„´
        val noisePattern = Regex("^[ì•„ì—ì´ì˜¤ìš°ìŒí í]+$")
        if (normalizedText.matches(noisePattern)) {
            Log.v(TAG, "FILTERED: ê°íƒ„ì‚¬ íŒ¨í„´ ($normalizedText)")
            return false
        }

        // ì¼ë°˜ì ì¸ ì¡ìŒ í‚¤ì›Œë“œ í¬í•¨ ê²€ì‚¬
        val commonNoiseKeywords = listOf("ì½œë¡", "ì—í—´", "ìŒ", "íìŒ", "ì–´", "ì•„", "ìŒ...", "ìŒ...")
        for (keyword in commonNoiseKeywords) {
            if (normalizedText.contains(keyword)) {
                // ì¡ìŒì´ í¬í•¨ëœ í…ìŠ¤íŠ¸ë¼ë„ ê¸¸ì´ê°€ ê¸¸ë©´ ìœ ì˜ë¯¸í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ê¸¸ì´ê°€ ì§§ê±°ë‚˜ (4ê¸€ì ë¯¸ë§Œìœ¼ë¡œ ì„¤ì •) í•´ë‹¹ í‚¤ì›Œë“œì™€ ë§¤ìš° ìœ ì‚¬í•  ê²½ìš°ì—ë§Œ í•„í„°ë§
                if (normalizedText.length < 4 || normalizedText == keyword.replace("...", "")) {
                    Log.v(TAG, "FILTERED: ì¼ë°˜ ì¡ìŒ í‚¤ì›Œë“œ í¬í•¨ ($normalizedText)")
                    return false
                }
            }
        }

        // ìœ„ í•„í„°ë¥¼ ëª¨ë‘ í†µê³¼í•˜ë©´ ìœ ì˜ë¯¸í•œ ë°œí™”ë¡œ ê°„ì£¼
        return true
    }

    /**
     * AudioRecordë¥¼ ì‹œì‘í•˜ê³ , STT ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­ì„ ì‹œì‘í•©ë‹ˆë‹¤.
     */
    @RequiresPermission(Manifest.permission.RECORD_AUDIO)
    private fun startStreamingAudio() {
        if (isListening) return
        isListening = true

        // AudioRecord ì´ˆê¸°í™”
        try {
            bufferSize = AudioRecord.getMinBufferSize(sampleRate, channelConfig, audioFormat)
            audioRecord = AudioRecord(
                MediaRecorder.AudioSource.MIC, sampleRate, channelConfig, audioFormat, bufferSize
            )
            audioRecord?.startRecording()
        } catch (e: Exception) {
            Log.e(TAG, "ë§ˆì´í¬ ì´ˆê¸°í™” ì‹¤íŒ¨: ${e.message}")
            isListening = false
            return
        }

        // [ìŠ¤ë ˆë“œ A] ì˜¤ë””ì˜¤ ë…¹ìŒ ìŠ¤ë ˆë“œ
        audioRecordingThread = Thread {
            Log.d(TAG, "[ìŠ¤ë ˆë“œ A] ë…¹ìŒ ì‹œì‘")
            val buffer = ByteArray(bufferSize)
            var errorCount = 0

            while (isListening) {
                try {
                    val readSize = audioRecord?.read(buffer, 0, buffer.size) ?: -1

                    if (readSize > 0) {
                        // ì •ìƒ: íì— ë°ì´í„° ë„£ê¸°
                        audioBuffer.offer(buffer.copyOf(readSize))
                        errorCount = 0 // ì„±ê³µí•˜ë©´ ì—ëŸ¬ ì¹´ìš´íŠ¸ ì´ˆê¸°í™”
                    } else {
                        // ë¹„ì •ìƒ: ì˜¤ë””ì˜¤ ì½ê¸° ì‹¤íŒ¨ ì˜ˆì™¸ ì²˜ë¦¬
                        Log.w(TAG, "[ìŠ¤ë ˆë“œ A] ì˜¤ë””ì˜¤ ì½ê¸° ì‹¤íŒ¨ (ì½”ë“œ: $readSize)")
                        errorCount++

                        // ì—°ì†ìœ¼ë¡œ ì—ëŸ¬ê°€ ë‚˜ë©´ ì ê¹ ì‰¬ì–´ì¤Œ (CPU ê³¼ë¶€í•˜ ë°©ì§€)
                        if (errorCount > 10) Thread.sleep(100)
                    }
                } catch (e: Exception) {
                    Log.e(TAG, "[ìŠ¤ë ˆë“œ A] ì¹˜ëª…ì  ì˜¤ë¥˜: ${e.message}")
                }
            }
            Log.d(TAG, "[ìŠ¤ë ˆë“œ A] ë…¹ìŒ ìŠ¤ë ˆë“œ ì¢…ë£Œ")
        }
        audioRecordingThread?.start()

        // [ìŠ¤ë ˆë“œ B] ì‹œì‘
        startSttTransmission()

        // ê°ì‹œì ê°€ë™ (í˜„ì¬ ì‹œê°„ìœ¼ë¡œ ì´ˆê¸°í™”)
        lastSttResponseTime = System.currentTimeMillis()
        watchdogHandler.removeCallbacks(watchdogRunnable)
        watchdogHandler.postDelayed(watchdogRunnable, 2000) // 2ì´ˆ ë’¤ë¶€í„° ê°ì‹œ ì‹œì‘

        // STOMP ì—°ê²° ìƒíƒœ í™•ì¸ ë° ì¬ì—°ê²°
        if (!stompClient.isConnected) {
            // ì´ë¯¸ onViewCreatedì—ì„œ ì—°ê²°í–ˆë”ë¼ë„, ì¤‘ê°„ì— ëŠê²¼ìœ¼ë©´ ë‹¤ì‹œ ì—°ê²° ì‹œë„
            stompClient.connect()
        }

        // UI ìŠ¤ë ˆë“œ ì‘ì—…
        activity?.runOnUiThread {
            binding.imageViewStop.visibility = View.VISIBLE
            Toast.makeText(requireContext(), "ë°œí‘œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.", Toast.LENGTH_SHORT).show()
        }
    }

    /**
     * [ìŠ¤ë ˆë“œ B] STT ì „ì†¡ ìŠ¤íŠ¸ë¦¼ ë° ìŠ¤ë ˆë“œë¥¼ (ì¬)ì‹œì‘í•©ë‹ˆë‹¤.
     */
    private fun startSttTransmission() {
        if (!isListening) return
        Log.d(TAG, "[ìŠ¤ë ˆë“œ B] STT ì „ì†¡ ìŠ¤íŠ¸ë¦¼ (ì¬)ì‹œì‘...")

        // ìŠ¤íŠ¸ë¦¼ ì—°ê²°
        try {
            requestObserver = speechClient?.streamingRecognizeCallable()?.bidiStreamingCall(responseObserver)

            val recognitionConfig = RecognitionConfig.newBuilder()
                .setEncoding(RecognitionConfig.AudioEncoding.LINEAR16)
                .setSampleRateHertz(sampleRate)
                .setLanguageCode("ko-KR")
                .setEnableAutomaticPunctuation(true)
                .build()
            val streamingConfig = StreamingRecognitionConfig.newBuilder()
                .setConfig(recognitionConfig)
                .setInterimResults(true)
                .build()
            val initialRequest = StreamingRecognizeRequest.newBuilder()
                .setStreamingConfig(streamingConfig)
                .build()

            requestObserver?.onNext(initialRequest)

            Thread.sleep(200)

        } catch (e: Exception) {
            Log.e(TAG, "[ìŠ¤ë ˆë“œ B] ìŠ¤íŠ¸ë¦¼ ì´ˆê¸°í™” ì‹¤íŒ¨: ${e.message}")
            return
        }

        // [ìŠ¤ë ˆë“œ B] ì „ì†¡ ë£¨í”„
        sttTransmissionThread = Thread {
            Log.d(TAG, "[ìŠ¤ë ˆë“œ B] ì „ì†¡ ë£¨í”„ ì§„ì…")
            while (isListening) {
                try {
                    // íì—ì„œ ë°ì´í„° êº¼ë‚´ê¸° (ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì—¬ê¸°ì„œ ëŒ€ê¸°)
                    val audioData = audioBuffer.take()

                    // STT ì „ì†¡
                    val request = StreamingRecognizeRequest.newBuilder()
                        .setAudioContent(ByteString.copyFrom(audioData))
                        .build()
                    requestObserver?.onNext(request)

                } catch (e: InterruptedException) {
                    Log.d(TAG, "[ìŠ¤ë ˆë“œ B] ì¸í„°ëŸ½íŠ¸ë¡œ ì¢…ë£Œ")
                    break
                } catch (e: Exception) {
                    // ìŠ¤íŠ¸ë¦¼ì´ ëŠê²¼ì„ ë•Œ ì£¼ë¡œ ë°œìƒ
                    Log.w(TAG, "[ìŠ¤ë ˆë“œ B] ì „ì†¡ ì¤‘ ì˜¤ë¥˜ (ì¬ì‹œì‘ ëŒ€ê¸°): ${e.message}")
                    break
                }
            }
            Log.d(TAG, "[ìŠ¤ë ˆë“œ B] ì „ì†¡ ìŠ¤ë ˆë“œ ì¢…ë£Œ")
        }
        sttTransmissionThread?.start()
    }

    /**
     * AudioRecordë¥¼ ì¤‘ì§€í•˜ê³ , STT ìŠ¤íŠ¸ë¦¬ë°ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.
     */
    private fun stopStreamingAudio() {
        if (!isListening) return

        // ê°ì‹œì ë¹„í™œì„±í™”
        watchdogHandler.removeCallbacks(watchdogRunnable)

        isListening = false

        // [ìŠ¤ë ˆë“œ A] ì¤‘ì§€ - ìŠ¤ë ˆë“œ ìì²´ë„ ì¤‘ë‹¨
        audioRecordingThread?.interrupt()
        audioRecord?.stop()
        audioRecord?.release()
        audioRecord = null
        audioRecordingThread = null

        // [ìŠ¤ë ˆë“œ B] ì¤‘ì§€
        // .take()ì—ì„œ ëŒ€ê¸° ì¤‘ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ interrupt()ë¡œ ê¹¨ì›Œì•¼ í•¨
        sttTransmissionThread?.interrupt()
        requestObserver?.onCompleted() // STT ì„œë²„ì— ì¢…ë£Œ ì•Œë¦¼
        requestObserver = null
        sttTransmissionThread = null

        // í ë¹„ìš°ê¸°
        audioBuffer.clear()

        // í…ìŠ¤íŠ¸ ë²„í¼ ë¹„ìš°ê¸°
        recognizedSpeechBuffer.setLength(0)

        // ì¢…ë£Œ ë©”ì‹œì§€
        binding.imageViewStop.visibility = View.GONE
        Toast.makeText(requireContext(), "ë°œí‘œê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.", Toast.LENGTH_SHORT).show()
    }

    // ì›¹ì†Œì¼“ìœ¼ë¡œ íŒíŠ¸ ë©”ì‹œì§€(í˜„ì¬ ë°œí™” ì¤‘ì¸ ë¬¸ì¥ idì™€ ë‚´ìš©, ìœ ì‚¬ë„, ì²˜ë¦¬ ì‹œê°„)ë¥¼ ìˆ˜ì‹ í–ˆì„ ë•Œ ì‹¤í–‰ë  ì½œë°± í•¨ìˆ˜
    private fun onHintReceived(response: SimilarityResponse) {
        Log.d(TAG, "ì„œë²„ì—ì„œ íŒíŠ¸ ìˆ˜ì‹ : ${response.mostSimilarId}")
        if (isAdded) {
            // íŒíŠ¸ë¥¼ UIì— í‘œì‹œ
            binding.textViewResult.text = ""
            binding.textViewResult.text = "ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì¥:\n${response.mostSimilarText}"

            speakingSentence = response.mostSimilarText
            speakingId = response.mostSimilarId
            binding.textViewNowspeaking.text = "í˜„ì¬ ë°œí™” ì¤‘ì¸ ë¬¸ì¥: \n ${speakingSentence}"

        }
    }

    private var lastNextScriptId: Int? = null

    // nextScriptIdì— ëŒ€í•œ ì •ë³´ê°€ ì˜¤ë©´ ì›Œì¹˜ë¡œ ì´ë¯¸ì§€ ë³´ëƒ„.
    private fun onProgressReceived(progress: ProgressResponse) {
        Log.d(TAG, "ì„œë²„ì—ì„œ ì§„í–‰ë¥  ê³„ì‚° ê²°ê³¼ ìˆ˜ì‹ : ${progress.nextScriptId}")

        val nextId = progress.nextScriptId ?: return

        val nextIdInt = nextId.toIntOrNull()
        if (nextIdInt == null) {
            Log.e(TAG, "nextScriptId ë³€í™˜ ì‹¤íŒ¨: $nextId")
            return
        }

        if (lastNextScriptId == nextIdInt) {
            Log.d(TAG, "nextScriptId ë™ì¼ â†’ ì²˜ë¦¬ ìŠ¤í‚µ")
            return
        }
        lastNextScriptId = nextIdInt

        viewLifecycleOwner.lifecycleScope.launch(Dispatchers.IO) {

            // 1. DBì—ì„œ IDë¡œ ì´ë¯¸ì§€ ì •ë³´ ì¡°íšŒ
            val entity = imageCacheDao.getByProjectAndSentence(PRESENTATION_ID.toInt(),nextIdInt)

            if (entity == null) {
                Log.e(TAG, "âŒ DBì— í•´ë‹¹ ID ì´ë¯¸ì§€ ì—†ìŒ: id=$nextIdInt")
                return@launch
            }

            val filePath = entity.filePath

            // 2. íŒŒì¼ â†’ Bitmap ë³µì›
            val bitmap = BitmapFactory.decodeFile(filePath)

            if (bitmap == null) {
                val file = File(filePath)
                Log.e(
                    TAG,
                    "âŒ Bitmap ë””ì½”ë”© ì‹¤íŒ¨: $filePath " +
                            "(exists=${file.exists()}, length=${file.length()}, lastModified=${file.lastModified()})"
                )
                return@launch
            }

            // 3. Bitmap â†’ ByteArray ë³€í™˜
            val byteStream = ByteArrayOutputStream()
            bitmap.compress(Bitmap.CompressFormat.JPEG, 90, byteStream)
            val imageBytes = byteStream.toByteArray()

            // 4. ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ ì›Œì¹˜ë¡œ ì „ì†¡
            withContext(Dispatchers.Main) {
                sendImageToWatch(imageBytes)
                Log.d(TAG, "âœ… ì›Œì¹˜ë¡œ ì´ë¯¸ì§€ ì „ì†¡ ì™„ë£Œ: id=$nextIdInt")
            }
        }
    }

    fun sendImageToWatch(imageBytes: ByteArray) {
        val path = "/image_display"

        val nodeClient = Wearable.getNodeClient(requireContext())
        val messageClient = Wearable.getMessageClient(requireContext())

        lifecycleScope.launch(Dispatchers.IO) {
            try {
                // ì—°ê²°ëœ ëª¨ë“  ì›Œì¹˜ ë…¸ë“œ ê°€ì ¸ì˜¤ê¸°
                val nodes = Tasks.await(nodeClient.connectedNodes)

                if (nodes.isEmpty()) {
                    Log.e(TAG, "âŒ ì—°ê²°ëœ ì›Œì¹˜ ë…¸ë“œ ì—†ìŒ")
                    return@launch
                }

                // ëª¨ë“  ì›Œì¹˜ë¡œ ì´ë¯¸ì§€ ì „ì†¡
                for (node in nodes) {
                    Tasks.await(
                        messageClient.sendMessage(
                            node.id,
                            path,
                            imageBytes
                        )
                    )

                    Log.d(TAG, "âœ… MessageClient ì´ë¯¸ì§€ ì „ì†¡ ì„±ê³µ â†’ nodeId=${node.id}")
                }

            } catch (e: Exception) {
                Log.e(TAG, "âŒ MessageClient ì´ë¯¸ì§€ ì „ì†¡ ì‹¤íŒ¨", e)
            }
        }
    }

    // url ê¸°ë°˜ìœ¼ë¡œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë°›ëŠ” í•¨ìˆ˜
    fun downloadBitmap(url: String): Bitmap {
        val connection = URL(url).openConnection() as HttpURLConnection
        connection.connectTimeout = 100000
        connection.readTimeout = 100000
        connection.doInput = true
        connection.connect()

        val inputStream = connection.inputStream
        val bitmap = BitmapFactory.decodeStream(inputStream)
        inputStream.close()

        if (bitmap == null) {
            throw IllegalStateException("âŒ Bitmap decode ì‹¤íŒ¨: $url")
        }

        return bitmap
    }

    // ë¹„íŠ¸ë§µ ì €ì¥.
    fun saveBitmap(context: Context, bitmap: Bitmap, projectId: Int, sentenceId: Int): String {
        val file = File(context.filesDir, "img_$projectId-$sentenceId.jpg")

        FileOutputStream(file).use { fos ->
            val success = bitmap.compress(Bitmap.CompressFormat.JPEG, 85, fos)
            if (!success) {
                throw IllegalStateException("âŒ Bitmap compress ì‹¤íŒ¨: id=$sentenceId")
            }
        }

        if (!file.exists() || file.length() == 0L) {
            throw IllegalStateException("âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: id=$sentenceId")
        }

        Log.d("ImageCache", "âœ… ì‹¤ì œ íŒŒì¼ ì €ì¥ ì„±ê³µ: ${file.absolutePath} (${file.length()} bytes)")
        return file.absolutePath
    }

    fun clearAllCachedImages(context: Context) {
        context.filesDir.listFiles()?.forEach { file ->
            if (file.name.startsWith("img_")) {
                file.delete()
            }
        }
    }



    override fun onDestroyView() {
        super.onDestroyView()

        // ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€
        if (isListening) {
            stopStreamingAudio()
        }

        // ì›¹ì†Œì¼“ ì—°ê²° í•´ì œ
        if (::stompClient.isInitialized) {
            stompClient.disconnect()
        }

        // STT í´ë¼ì´ì–¸íŠ¸ í•´ì œ
        speechClient?.shutdown()
        speechClient?.awaitTermination(5, java.util.concurrent.TimeUnit.SECONDS)
        speechClient = null

        _binding = null
    }

    private fun trimSpeechBufferIfNeeded() {
        // ë²„í¼ë¥¼ ê³µë°±ì„ ê¸°ì¤€ìœ¼ë¡œ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ë¡œ ë¶„ë¦¬
        val words = recognizedSpeechBuffer.toString().trim().split("\\s+".toRegex())

        if (words.size > MAX_WORD_COUNT) {
            Log.d(TAG, "ë²„í¼ ë‹¨ì–´ ìˆ˜ ì´ˆê³¼ (${words.size}ê°œ). ì•ë¶€ë¶„ ${TRIM_WORD_COUNT}ê°œ ì‚­ì œ.")

            // ìµœì‹  ë‚´ìš© (words.size - TRIM_WORD_COUNT)ê°œë§Œ ìœ ì§€
            val newWords = words.subList(TRIM_WORD_COUNT, words.size)

            // ë²„í¼ë¥¼ ìƒˆë¡œìš´ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ë¡œ ì¬êµ¬ì„±
            recognizedSpeechBuffer.clear()
            recognizedSpeechBuffer.append(newWords.joinToString(" "))
        }
    }
}